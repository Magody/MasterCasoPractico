{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── .env\n",
      "├── .env.example\n",
      "├── .gitignore\n",
      "├── .vscode/\n",
      "│   ├── launch.json\n",
      "│   ├── settings.json\n",
      "├── app_backend.py\n",
      "├── app_frontend_vtuber_studio.py\n",
      "├── assets/\n",
      "│   ├── score_2025-04-26.png\n",
      "├── datasets/\n",
      "│   ├── curated/\n",
      "│   │   ├── mirai/\n",
      "│   │   │   ├── parts/\n",
      "│   │   │   │   ├── dataset_about_mirai.jsonl\n",
      "│   │   │   │   ├── dataset_funny_questions.jsonl\n",
      "│   │   │   ├── test/\n",
      "│   │   │   │   ├── dataset.jsonl\n",
      "│   │   │   ├── train/\n",
      "│   │   │   │   ├── dataset.jsonl\n",
      "│   │   │   │   ├── MirAI-Dataset - Foundations - test.csv\n",
      "│   │   │   │   ├── MirAI-Dataset - Foundations.csv\n",
      "├── dataset_consolidator.ipynb\n",
      "├── dev/\n",
      "│   ├── prompting/\n",
      "│   │   ├── directory_util.ipynb\n",
      "│   │   ├── README_general_prompt.md\n",
      "│   ├── qlora/\n",
      "│   │   ├── dev_mirAI_v0_qlora_instruct.ipynb\n",
      "│   │   ├── outputs/\n",
      "│   │   │   ├── runs/\n",
      "│   │   │   │   ├── May05_21-22-46_magod/\n",
      "│   │   │   │   │   ├── events.out.tfevents.1746498167.magod.85476.0\n",
      "│   ├── rlhf/\n",
      "│   │   ├── dev_dpo.ipynb\n",
      "│   ├── testing/\n",
      "│   ├── tts/\n",
      "│   │   ├── dev_voice_f5-tts.ipynb\n",
      "│   │   ├── dev_voice_kokoro.ipynb\n",
      "├── dev_check_performance.ipynb\n",
      "├── directory_util.ipynb\n",
      "├── logs/\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs4_ga2_ep10_seed4242_warm10_20250513_183236/\n",
      "│   │   ├── events.out.tfevents.1747179167.magod.36045.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep10_seed4242_warm10_20250506_005528/\n",
      "│   │   ├── events.out.tfevents.1746510965.magod.1359.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep10_seed4242_warm10_20250513_170105/\n",
      "│   │   ├── events.out.tfevents.1747173683.magod.98363.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep10_seed4242_warm10_20250513_181803/\n",
      "│   │   ├── events.out.tfevents.1747178302.magod.24030.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep10_seed4242_warm10_20250513_182324/\n",
      "│   │   ├── events.out.tfevents.1747178615.magod.26060.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep10_seed4242_warm10_20250513_182939/\n",
      "│   │   ├── events.out.tfevents.1747178996.magod.34753.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora32_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_013300/\n",
      "│   │   ├── events.out.tfevents.1748500395.magod.3860.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep10_seed1244_warm10_do5e-02_20250529_184358/\n",
      "│   │   ├── events.out.tfevents.1748562254.magod.40076.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep3_seed4242_warm10_do5e-02_20250513_191634/\n",
      "│   │   ├── events.out.tfevents.1747181813.magod.45724.0\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_010626/\n",
      "│   │   ├── events.out.tfevents.1748498805.magod.96345.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_220946/\n",
      "│   │   ├── events.out.tfevents.1746500999.magod.10146.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_231140/\n",
      "│   │   ├── events.out.tfevents.1746504713.magod.31560.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_231418/\n",
      "│   │   ├── events.out.tfevents.1746504870.magod.32534.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_232258/\n",
      "│   │   ├── events.out.tfevents.1746505388.magod.37037.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_232413/\n",
      "│   │   ├── events.out.tfevents.1746505464.magod.37818.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_232535/\n",
      "│   │   ├── events.out.tfevents.1746505545.magod.38718.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250505_232642/\n",
      "│   │   ├── events.out.tfevents.1746505611.magod.39542.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250506_000245/\n",
      "│   │   ├── events.out.tfevents.1746507776.magod.66548.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250506_001236/\n",
      "│   │   ├── events.out.tfevents.1746508368.magod.73708.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250506_001315/\n",
      "│   │   ├── events.out.tfevents.1746508404.magod.74346.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250506_001509/\n",
      "│   │   ├── events.out.tfevents.1746508521.magod.75432.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_20250506_005114/\n",
      "│   │   ├── events.out.tfevents.1746510688.magod.98740.0\n",
      "│   ├── Llama-3_2-3B-bnb-4bit_lora64_bs4_ga2_ep3_seed4242_warm10_20250426_160029/\n",
      "│   │   ├── events.out.tfevents.1745701241.Magody.135420.0\n",
      "│   ├── Meta-Llama-3_1-8B-bnb-4bit_lora128_bs2_ga4_ep5_seed4242_warm10_do5e-02_20250505_220343/\n",
      "│   │   ├── events.out.tfevents.1746500651.magod.7232.0\n",
      "│   ├── Meta-Llama-3_1-8B-bnb-4bit_lora128_bs4_ga2_ep10_seed4242_warm100_do5e-02_20250426_161836/\n",
      "│   │   ├── events.out.tfevents.1745702329.Magody.150488.0\n",
      "│   ├── Meta-Llama-3_1-8B-bnb-4bit_lora128_bs4_ga2_ep10_seed4242_warm100_do5e-02_20250505_200006/\n",
      "│   │   ├── events.out.tfevents.1746493688.magod.37282.0\n",
      "│   ├── Meta-Llama-3_1-8B-bnb-4bit_lora128_bs8_ga2_ep5_seed4242_warm10_do5e-02_20250505_220138/\n",
      "│   │   ├── events.out.tfevents.1746500526.magod.5287.0\n",
      "│   ├── Meta-Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep5_seed4242_warm10_20250426_160516/\n",
      "│   │   ├── events.out.tfevents.1745702035.Magody.138211.0\n",
      "├── models/\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora32_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_013300/\n",
      "│   │   ├── adapter_config.json\n",
      "│   │   ├── adapter_model.safetensors\n",
      "│   │   ├── checkpoint-145/\n",
      "│   │   │   ├── adapter_config.json\n",
      "│   │   │   ├── adapter_model.safetensors\n",
      "│   │   │   ├── optimizer.pt\n",
      "│   │   │   ├── README.md\n",
      "│   │   │   ├── rng_state.pth\n",
      "│   │   │   ├── scheduler.pt\n",
      "│   │   │   ├── special_tokens_map.json\n",
      "│   │   │   ├── tokenizer.json\n",
      "│   │   │   ├── tokenizer_config.json\n",
      "│   │   │   ├── trainer_state.json\n",
      "│   │   │   ├── training_args.bin\n",
      "│   │   ├── loss.txt\n",
      "│   │   ├── README.md\n",
      "│   │   ├── special_tokens_map.json\n",
      "│   │   ├── tokenizer.json\n",
      "│   │   ├── tokenizer_config.json\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep10_seed1244_warm10_do5e-02_20250529_184358/\n",
      "│   │   ├── adapter_config.json\n",
      "│   │   ├── adapter_model.safetensors\n",
      "│   │   ├── checkpoint-290/\n",
      "│   │   │   ├── adapter_config.json\n",
      "│   │   │   ├── adapter_model.safetensors\n",
      "│   │   │   ├── optimizer.pt\n",
      "│   │   │   ├── README.md\n",
      "│   │   │   ├── rng_state.pth\n",
      "│   │   │   ├── scheduler.pt\n",
      "│   │   │   ├── special_tokens_map.json\n",
      "│   │   │   ├── tokenizer.json\n",
      "│   │   │   ├── tokenizer_config.json\n",
      "│   │   │   ├── trainer_state.json\n",
      "│   │   │   ├── training_args.bin\n",
      "│   │   ├── README.md\n",
      "│   │   ├── special_tokens_map.json\n",
      "│   │   ├── tokenizer.json\n",
      "│   │   ├── tokenizer_config.json\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep3_seed4242_warm10_do5e-02_20250513_191634/\n",
      "│   │   ├── adapter_config.json\n",
      "│   │   ├── adapter_model.safetensors\n",
      "│   │   ├── checkpoint-81/\n",
      "│   │   │   ├── adapter_config.json\n",
      "│   │   │   ├── adapter_model.safetensors\n",
      "│   │   │   ├── optimizer.pt\n",
      "│   │   │   ├── README.md\n",
      "│   │   │   ├── rng_state.pth\n",
      "│   │   │   ├── scheduler.pt\n",
      "│   │   │   ├── special_tokens_map.json\n",
      "│   │   │   ├── tokenizer.json\n",
      "│   │   │   ├── tokenizer_config.json\n",
      "│   │   │   ├── trainer_state.json\n",
      "│   │   │   ├── training_args.bin\n",
      "│   │   ├── README.md\n",
      "│   │   ├── special_tokens_map.json\n",
      "│   │   ├── tokenizer.json\n",
      "│   │   ├── tokenizer_config.json\n",
      "│   ├── Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_010626/\n",
      "│   │   ├── adapter_config.json\n",
      "│   │   ├── adapter_model.safetensors\n",
      "│   │   ├── checkpoint-145/\n",
      "│   │   │   ├── adapter_config.json\n",
      "│   │   │   ├── adapter_model.safetensors\n",
      "│   │   │   ├── optimizer.pt\n",
      "│   │   │   ├── README.md\n",
      "│   │   │   ├── rng_state.pth\n",
      "│   │   │   ├── scheduler.pt\n",
      "│   │   │   ├── special_tokens_map.json\n",
      "│   │   │   ├── tokenizer.json\n",
      "│   │   │   ├── tokenizer_config.json\n",
      "│   │   │   ├── trainer_state.json\n",
      "│   │   │   ├── training_args.bin\n",
      "│   │   ├── loss.txt\n",
      "│   │   ├── README.md\n",
      "│   │   ├── special_tokens_map.json\n",
      "│   │   ├── tokenizer.json\n",
      "│   │   ├── tokenizer_config.json\n",
      "├── poc_backend/\n",
      "│   ├── discord/\n",
      "│   │   ├── .env\n",
      "│   │   ├── chat_client.py\n",
      "│   │   ├── config.py\n",
      "│   │   ├── discord_bot.py\n",
      "│   │   ├── main.py\n",
      "│   │   ├── tts_engine.py\n",
      "│   ├── interact_backend.py\n",
      "│   ├── README.md\n",
      "│   ├── test_endpoint.sh\n",
      "├── poc_frontend/\n",
      "│   ├── .env\n",
      "│   ├── .vscode/\n",
      "│   │   ├── launch.json\n",
      "│   ├── dev.ipynb\n",
      "│   ├── main.py\n",
      "│   ├── README.md\n",
      "│   ├── requirements.txt\n",
      "│   ├── src/\n",
      "│   │   ├── api/\n",
      "│   │   │   ├── routes.py\n",
      "│   │   ├── bots/\n",
      "│   │   │   ├── discord_bot.py\n",
      "│   │   │   ├── obs_relay.py\n",
      "│   │   ├── cli.py\n",
      "│   │   ├── config.py\n",
      "│   │   ├── pipeline/\n",
      "│   │   │   ├── chat_pipeline.py\n",
      "│   │   ├── services/\n",
      "│   │   │   ├── audio.py\n",
      "│   │   │   ├── llm_client.py\n",
      "│   │   │   ├── tts/\n",
      "│   │   │   │   ├── tts_eleven.py\n",
      "│   │   │   │   ├── tts_kokoro.py\n",
      "│   │   │   │   ├── tts_provider.py\n",
      "│   │   │   ├── vtuber.py\n",
      "│   │   │   ├── whisper.py\n",
      "│   │   ├── ui/\n",
      "│   │   │   ├── templates/\n",
      "│   │   │   │   ├── index.html\n",
      "│   │   │   │   ├── static/\n",
      "│   │   │   │   │   ├── js/\n",
      "│   │   │   │   │   │   ├── app.js\n",
      "│   │   ├── utils/\n",
      "│   │   │   ├── audio_fx.py\n",
      "│   │   │   ├── device_finder.py\n",
      "│   │   │   ├── kokoro_engine.py\n",
      "│   │   │   ├── voice_activity_detector.py\n",
      "│   │   │   ├── vtuber_studio.py\n",
      "│   ├── static/\n",
      "│   │   ├── kokoro/\n",
      "│   │   │   ├── voices/\n",
      "│   │   │   │   ├── af_alloy.pt\n",
      "│   │   │   │   ├── af_aoede.pt\n",
      "│   │   │   │   ├── af_bella.pt\n",
      "│   │   │   │   ├── af_heart.pt\n",
      "│   │   │   │   ├── af_jessica.pt\n",
      "│   │   │   │   ├── af_kore.pt\n",
      "│   │   │   │   ├── af_nicole.pt\n",
      "│   │   │   │   ├── af_nova.pt\n",
      "│   │   │   │   ├── af_river.pt\n",
      "│   │   │   │   ├── af_sarah.pt\n",
      "│   │   │   │   ├── af_sky.pt\n",
      "│   │   │   │   ├── am_adam.pt\n",
      "│   │   │   │   ├── am_echo.pt\n",
      "│   │   │   │   ├── am_eric.pt\n",
      "│   │   │   │   ├── am_fenrir.pt\n",
      "│   │   │   │   ├── am_liam.pt\n",
      "│   │   │   │   ├── am_michael.pt\n",
      "│   │   │   │   ├── am_onyx.pt\n",
      "│   │   │   │   ├── am_puck.pt\n",
      "│   │   │   │   ├── am_santa.pt\n",
      "│   │   │   │   ├── bf_alice.pt\n",
      "│   │   │   │   ├── bf_emma.pt\n",
      "│   │   │   │   ├── bf_isabella.pt\n",
      "│   │   │   │   ├── bf_lily.pt\n",
      "│   │   │   │   ├── bm_daniel.pt\n",
      "│   │   │   │   ├── bm_fable.pt\n",
      "│   │   │   │   ├── bm_george.pt\n",
      "│   │   │   │   ├── bm_lewis.pt\n",
      "│   │   │   │   ├── ef_dora.pt\n",
      "│   │   │   │   ├── em_alex.pt\n",
      "│   │   │   │   ├── em_santa.pt\n",
      "│   │   │   │   ├── ff_siwis.pt\n",
      "│   │   │   │   ├── hf_alpha.pt\n",
      "│   │   │   │   ├── hf_beta.pt\n",
      "│   │   │   │   ├── hm_omega.pt\n",
      "│   │   │   │   ├── hm_psi.pt\n",
      "│   │   │   │   ├── if_sara.pt\n",
      "│   │   │   │   ├── im_nicola.pt\n",
      "│   │   │   │   ├── jf_alpha.pt\n",
      "│   │   │   │   ├── jf_gongitsune.pt\n",
      "│   │   │   │   ├── jf_nezumi.pt\n",
      "│   │   │   │   ├── jf_tebukuro.pt\n",
      "│   │   │   │   ├── jm_kumo.pt\n",
      "│   │   │   │   ├── pf_dora.pt\n",
      "│   │   │   │   ├── pm_alex.pt\n",
      "│   │   │   │   ├── pm_santa.pt\n",
      "│   │   │   │   ├── zf_xiaobei.pt\n",
      "│   │   │   │   ├── zf_xiaoni.pt\n",
      "│   │   │   │   ├── zf_xiaoxiao.pt\n",
      "│   │   │   │   ├── zf_xiaoyi.pt\n",
      "│   ├── token.txt\n",
      "├── poetry.lock\n",
      "├── pyproject.toml\n",
      "├── README.blackwell.md\n",
      "├── README.md\n",
      "├── requirements.txt\n",
      "├── results/\n",
      "│   ├── gauges_Llama-3_1-8B-bnb-4bit_lora32_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_013300.png\n",
      "│   ├── gauges_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep10_seed1244_warm10_do5e-02_20250529_184358.png\n",
      "│   ├── gauges_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep3_seed4242_warm10_do5e-02_20250513_191634.png\n",
      "│   ├── gauges_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_010626.png\n",
      "│   ├── performance_Llama-3_1-8B-bnb-4bit_lora32_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_013300.csv\n",
      "│   ├── performance_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep10_seed1244_warm10_do5e-02_20250529_184358.csv\n",
      "│   ├── performance_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep3_seed4242_warm10_do5e-02_20250513_191634.csv\n",
      "│   ├── performance_Llama-3_1-8B-bnb-4bit_lora64_bs4_ga2_ep5_seed4243_warm10_do5e-02_20250529_010626.csv\n",
      "├── run_backend.sh\n",
      "├── src/\n",
      "│   ├── config/\n",
      "│   │   ├── q_lora_config.py\n",
      "│   ├── dataset_manager/\n",
      "│   │   ├── base_dataset_manager.py\n",
      "│   │   ├── plugins/\n",
      "│   │   │   ├── dataset_foundations_plugin.py\n",
      "│   ├── LightEvaluator.py\n",
      "│   ├── main/\n",
      "│   │   ├── inference/\n",
      "│   │   │   ├── main_prediction.py\n",
      "│   │   │   ├── main_prediction_base_custom.py\n",
      "│   │   ├── training/\n",
      "│   │   │   ├── main_grpo.py\n",
      "│   │   │   ├── main_training_base.py\n",
      "│   │   │   ├── main_training_base_custom.py\n",
      "│   │   │   ├── main_training_instruct.py\n",
      "│   ├── model_manager/\n",
      "│   │   ├── q_lora_model_manager.py\n",
      "│   ├── utils/\n",
      "│   │   ├── evaluation_utils.py\n",
      "│   │   ├── training_utils.py\n",
      "├── TASKs.md\n",
      "├── token.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_structure(root_dir, indent=\"\", exclude_dirs=None):\n",
    "    \"\"\"\n",
    "    Imprime la estructura del directorio excluyendo carpetas específicas de forma recursiva.\n",
    "\n",
    "    Parameters:\n",
    "    - root_dir: str, el directorio raíz.\n",
    "    - indent: str, la indentación para la estructura (usada en llamadas recursivas).\n",
    "    - exclude_dirs: list, lista de directorios a excluir de la estructura.\n",
    "    \"\"\"\n",
    "    exclude_dirs = exclude_dirs or []  # Lista de exclusión predeterminada\n",
    "\n",
    "    for item in os.listdir(root_dir):\n",
    "        path = os.path.join(root_dir, item)\n",
    "        \n",
    "        # Omitir directorios en la lista de exclusión\n",
    "        if os.path.isdir(path) and item in exclude_dirs:\n",
    "            continue\n",
    "\n",
    "        if os.path.isdir(path):\n",
    "            print(f\"{indent}├── {item}/\")\n",
    "            print_directory_structure(path, indent + \"│   \", exclude_dirs)\n",
    "        else:\n",
    "            if item not in exclude_dirs:\n",
    "                print(f\"{indent}├── {item}\")\n",
    "\n",
    "# Cambia `root_dir` por el path de tu proyecto y ajusta `exclude_dirs`\n",
    "root_dir_backend = \".\"\n",
    "\n",
    "exclude_dirs = [\n",
    "    \"mlruns\", \".git/\",\n",
    "    \".git\", \"__pycache__\", \".next\", \"node_modules\",\n",
    "    \".pytest_cache\", '__init__.py',\n",
    "    'effycentai_framework_core_llm',\n",
    "    'effycentai_framework_llm_openai',\n",
    "    'effycentai_framework_preprocessing_documents',\n",
    "    'README_dev.md', 'temp', 'bash_git_0.sh'\n",
    "    'dev.ipynb', '.flake8', '.github', '.python-version',\n",
    "    'dev_utils', 'frontend-websockets-test', '.ruff_cache',\n",
    "    '.venv', 'logs/', 'unsloth_compiled_cache/',\n",
    "    'unsloth_compiled_cache'\n",
    "]  # Agrega aquí las carpetas que quieres excluir\n",
    "print_directory_structure(root_dir_backend, exclude_dirs=exclude_dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chart_category': 'categories',\n",
       " 'chart_type': 'bar',\n",
       " 'sql': \"WITH monthly_totals AS (\\n            SELECT\\n                DATE_TRUNC('month', order_date) AS month_date,\\n                SUM(revision_count) AS total_revisions\\n            FROM\\n                silver.dp_purchase_orders_manufacters\\n            GROUP BY\\n                DATE_TRUNC('month', order_date)\\n        ),\\n        percentages AS (\\n            SELECT\\n                DATE_TRUNC('month', po.order_date) AS month_date,\\n                po.revision_count,\\n                CASE\\n                    WHEN mt.total_revisions = 0 THEN 0\\n                    ELSE (po.revision_count::float / NULLIF(mt.total_revisions, 0)) * 100\\n                END AS revision_percentage\\n            FROM\\n                silver.dp_purchase_orders_manufacters po\\n            JOIN\\n                monthly_totals mt ON DATE_TRUNC('month', po.order_date) = mt.month_date\\n        )\\n        SELECT\\n            TO_CHAR(month_date, 'YYYY-MM') AS category,\\n            AVG(revision_percentage) AS value\\n        FROM\\n            percentages\\n        GROUP BY\\n            month_date\\n        ORDER BY\\n            category;\"}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantum_backend.utils.lib.agents.LLMHighChartsAgent import LLMHighChartsAgent\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_xml_data(response: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parse the LLM response as XML. Expected XML structure:\n",
    "\n",
    "        <response>\n",
    "            <chart_category>...</chart_category>\n",
    "            <chart_type>...</chart_type>\n",
    "            <sql><![CDATA[...]]></sql>\n",
    "        </response>\n",
    "\n",
    "        Returns a dict with keys 'chart_category', 'chart_type', and 'sql' if successful; otherwise None.\n",
    "\n",
    "        This improved version:\n",
    "        - Removes markdown code fences (e.g., ```xml ... ```).\n",
    "        - Strips extraneous whitespace.\n",
    "        - Logs detailed error information if parsing fails.\n",
    "        \"\"\"\n",
    "        # Trim whitespace from the response\n",
    "        cleaned_response = response.strip()\n",
    "\n",
    "        # Remove markdown code fences if present (handles ``` or ```xml)\n",
    "        if cleaned_response.startswith(\"```\"):\n",
    "            # Remove starting fence (optional language specifier)\n",
    "            cleaned_response = re.sub(r\"^```(?:xml)?\\s*\", \"\", cleaned_response)\n",
    "            # Remove trailing fence\n",
    "            cleaned_response = re.sub(r\"\\s*```$\", \"\", cleaned_response)\n",
    "\n",
    "        try:\n",
    "            root = ET.fromstring(cleaned_response)\n",
    "        except ET.ParseError as e:\n",
    "            print(\n",
    "                f\"Error parsing XML: {e}. Response content: {cleaned_response}\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        chart_category = (root.findtext(\"chart_category\") or \"value\").strip().lower()\n",
    "        chart_type = (root.findtext(\"chart_type\") or \"value\").strip().lower()\n",
    "        sql_text = (root.findtext(\"sql\") or \"\").strip()\n",
    "\n",
    "        # Clean the SQL text by removing CDATA markers if present.\n",
    "        sql_text = LLMHighChartsAgent.clean_sql_text(sql_text)\n",
    "        sql_query = LLMHighChartsAgent.extract_sql_from_response(sql_text)\n",
    "\n",
    "        return {\n",
    "            \"chart_category\": chart_category,\n",
    "            \"chart_type\": chart_type,\n",
    "            \"sql\": sql_query,\n",
    "        }\n",
    "\n",
    "extract_xml_data(\"\"\"<response>\n",
    "    <sql><![CDATA[\n",
    "        WITH monthly_totals AS (\n",
    "            SELECT\n",
    "                DATE_TRUNC('month', order_date) AS month_date,\n",
    "                SUM(revision_count) AS total_revisions\n",
    "            FROM\n",
    "                silver.dp_purchase_orders_manufacters\n",
    "            GROUP BY\n",
    "                DATE_TRUNC('month', order_date)\n",
    "        ),\n",
    "        percentages AS (\n",
    "            SELECT\n",
    "                DATE_TRUNC('month', po.order_date) AS month_date,\n",
    "                po.revision_count,\n",
    "                CASE\n",
    "                    WHEN mt.total_revisions = 0 THEN 0\n",
    "                    ELSE (po.revision_count::float / NULLIF(mt.total_revisions, 0)) * 100\n",
    "                END AS revision_percentage\n",
    "            FROM\n",
    "                silver.dp_purchase_orders_manufacters po\n",
    "            JOIN\n",
    "                monthly_totals mt ON DATE_TRUNC('month', po.order_date) = mt.month_date\n",
    "        )\n",
    "        SELECT\n",
    "            TO_CHAR(month_date, 'YYYY-MM') AS category,\n",
    "            AVG(revision_percentage) AS value\n",
    "        FROM\n",
    "            percentages\n",
    "        GROUP BY\n",
    "            month_date\n",
    "        ORDER BY\n",
    "            category;\n",
    "    ]]></sql>\n",
    "    <chart_category>categories</chart_category>\n",
    "    <chart_type>bar</chart_type>\n",
    "</response>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirai-uLPtLm8D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
